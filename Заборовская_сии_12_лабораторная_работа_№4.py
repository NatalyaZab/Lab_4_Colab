# -*- coding: utf-8 -*-
"""Заборовская_СИИ-12_Лабораторная работа №4

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wT1rk7hx2nRaJn-qJ6FAjju2rMUqREPA

**Бизнес-постановка задачи**
В отелях часто бронирют номера, не заселяясь в итоге. В результате этого компания недополучает прибыль. У нас есть выборка данных по бронированию отеля с результатами бронирования - заселился клиент или отменил бронь.
 Мы предлагаем построить модель, которая будет прогнозировать возможность отмены бронирования, а также позволит выявить причины этого.

Такая модель позволит одновременно улучшить прибыль компании, а также покажет, на какие категории клиентов необходимо ориентироваться, а каким категориям - разработать дополнительные условия.

**Постановка задачи анализа данных**

Целью данной задачи является построение модели классификации клиентов: на вход модель будет принимать данные о бронировании и о клиенте, а на выходе она должна работать в двух режимах:

 - выдавать вероятность отмены бронирования для данного клиента,
 - выдавать правильный с точки зрения модели класс клиента (отменит бронь или
заселится).

**Обзор доступных данных**

В выборке 119390 исторических наблюдений и 36 переменных, одна из которых - целевая. Таким образом, про каждого из 119390 клиентов мы знаем значения 36 их характеристик, в том числе значение целевой переменной: отменил клиент бронь или нет.

**Доступные признаки**

Данные содержат два типа переменных:

Целевая: is canceled, заселился клиент или отменил бронь. Остальные переменные: 35 переменных, могут использоваться для прогноза целевой переменной.
Выборка содержит следующие признаки:
1. hotel - наименование отеля
2. is_canceled - отменен
3. lead_time - время выполнения заказа
4. arrival_date_year - год прибытия
5. arrival_date_month - месяц прибытия
6. arrival_date_week_number - номер недели прибытия
7. arrival_date_day_of_month - день месяца прибытия
8. stays_in_weekend_nights - остается  в выходные ночи
9. stays_in_week_nights - остается  в будние ночи
10. adults - взрослые
11. children - дети
12. babies младенцы
13. meal - тип питания
14. country -страна
15. market_segment - сегмент рынка
16. distribution_channel - канал распределения
17. is_repeated_guest - постоянный гость
18. previous_cancellations -предыдущие отмены
19. previous_bookings_not_canceled - предыдущие бронирования не отменены
20. reserved_room_type - зарезерированный тип номера
21. assigned_room_type - присвоенный тип номера
22. booking_changes - бронирование замены
23. deposit_type - тип депозита
24. agent - агент
25. company - компания
26. days_in_waiting_list - дней в листе ожидания
27. customer_type - тип клиента
28. adr - средняя цена одной ночи
29. required_car_parking_spaces - необходимое количество парковочных мест
30. total_of_special_requests - общее количество специальных запросов
31. reservation_status - статус бронирования
32. reservation_status_date - дата бронирования
33. name - имя
34. email - электронная почта
35. phone-number - телефонный номер
36. credit_card - номер карты
"""

# импортируем библиотеки
import numpy as np
import matplotlib.pyplot as plt 
import pandas as pd

"""Библиотека scikit-learn -- де факто наиболее популярный, разносторонний, хорошо документированный и постоянно обогащающийся инструмент для построения моделей машинного обучения.

Выберем из него несколько готовых функции для расчёта метрик качества классификации.

"""

from sklearn.metrics import roc_curve, precision_recall_curve, auc # метрики качества
from sklearn.metrics import confusion_matrix, accuracy_score # метрики качества
from sklearn.metrics import average_precision_score # метрики качества

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt

import seaborn as sns
sns.set_style('whitegrid')

# применим функцию read_csv() и посмотрим на первые 10 записей файла hotels.csv
# данные запишем в переменную 
hotel = pd.read_csv('hotel_booking.csv')
hotel.sample(10, random_state=123)

# посмотрим на составляющие датасета
hotel.keys()

hotel.shape #посмотрим на размерность датасета - 36 колонок и 119390 записей

"""Начнем с проверки общей информации о данных. Для того чтобы это сделать, нужно обратиться вызвать у переменной training_data метод info().

"""

hotel.info()

"""Пропусков в данных не так много: только у столбцов children, agent, country и company.
В данных присутствует три типа dtypes:

 - int64 - целое число (16 столбцов)
 - float64 - дробное число (4 столбца)
 - object - не число, обычно текст (16 столбцов)
"""

hotel.nunique() #посмотрим количеколичество уникальных значений

baby = 'babies' #посмотрим какие значения содержит столбец 'babies'
childrenvalues = hotel[baby]
childrenvalues.value_counts()

"""Так как бОльшая часть данных соответствует значению "0", то смысла рассматривать данную переменную нет."""

# проверим, совпадают ли столбцы по значению is_canceled, reservation_status и deposit_type
hotel_df = pd.DataFrame(hotel, columns = ['is_canceled', 'reservation_status', 'deposit_type'])
# посмотрим на первые пять наблюдений
hotel_df.sample(10, random_state=123)

"""Cтолбцы совпадают, разница лишь в типах данных - значению Check-Out соответствует 0, Canceled - 1.
Non refund всегда соответствует Canceled и 1.
"""

import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
plt.figure(figsize = (20,10))
# Посмотрим, на сколько влияет месяц заселения на отмену бронирования
sns.countplot(x = 'arrival_date_month', hue = 'is_canceled', data = hotel)
plt.xlabel('Месяц заселения', fontsize = 16)
plt.ylabel('Количество клиентов', fontsize = 16)
plt.title('Зависимость месяца заселения и отмены бронирования', fontsize = 16)

"""По данному графику можно сделать вывод, что в зависимость между месяцем заселения и отменой бронирования высокая.

Для числовых признаков можно построить гистограмму. Гистограмма - это способ графического представления табличных данных, благодаря которому можно увидеть распределение значений признака.

Для построения гистограммы необходимо вызвать метод hist() у объекта training_data. Желательно указать аргумент figsize, который устанавливает ожидаемый размер изображения. В нашем случае это (15,15).

Заметим, что название переменной, по которой строится гистограмма, указано в названии графика.
"""

hotel.hist(figsize=(15, 15));

"""Из гистограммы видно, что у нас в таких признаках как babies, children, previous_cancellations, previous_bookings_not_canceled, days_in_waiting_list, required_car_parking_spaces, is_repeated_guest нет достаточных данных по различным значениям, то рассматривать их не будем. По признаку 'babies' это уже рассматривалось ранее на функции value_counts.
По признаку 'country' 177 уникальных значений. При кодировании данного категориального признака данные могт исказиться, поэтому также удалим этот столбец.

Так как по признаку company пропусков более 50%, то рассматривать его тоже не будем.
  Убираем дублирующие is canceled признаки reservation_status, deposit_type.
  Также признак arrival_date_week_number частично дублирует arrival_date_month.
Такие признаки как reservation_status_date, name, email, phone-number, credit_card и arrival_date_year не повлияют на целевую переменную.
"""

hotel_data = hotel.drop(['babies', 'children', 'country', 'is_repeated_guest', 'previous_cancellations', 'required_car_parking_spaces', 'name', 'previous_bookings_not_canceled', 'days_in_waiting_list', 'company', 'reservation_status', 'deposit_type', 'arrival_date_week_number', 'reservation_status_date', 'email', 'phone-number', 'credit_card', 'arrival_date_year'], axis=1)
hotel_data.sample(10, random_state=123)

"""**Посмотрим общую статистику по данным**

Посмотрим на технические параметры загруженных данных для обучения. Для этого вызовем метод describe() для набора данных training_data

Для удобства отображения мы транспонируем результат: меняем местами столбцы и строки.
"""

hotel_data.describe().T

"""Обратим внимание на общие статистики показателей в данных:

count -- количество значений, которые не являются пропущенными (NaN);
mean, std -- среднее и разброс данных в соответствующем поле;
остальные статистики -- минимальное и максимальное значения, и квантили.
Из таких характеристик столбцов мы уже можем извлечь некоторую информацию о данных:

У столбца is_canceled среднее 0.370416. Значит, в нашей выборке у 37% клиентов отмена бронирования.
У столбца agent заполнено только 103050 значений из 119390. У столбца country - 118902 значений из 119390.

"""

hotel_data.info()

"""Поскольку алгоритмы машинного обучения работают лишь с числовыми признаками, необходимо  категориальные признаки перевести в числовые. Для этого выделим их в отдельный датафрейм."""

categorical_data1 = hotel_data.select_dtypes(include=['object']) # 1-й метод объединения категориальных признаков 
categorical_data1.sample(10, random_state=123)

categorical_data = pd.DataFrame(hotel_data, columns = ['hotel', 'arrival_date_month', 'meal', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type', 'customer_type'])
# посмотрим на первые пять наблюдений
categorical_data.sample(10, random_state=123)

categorical_data.nunique()

dummy_features = pd.get_dummies(categorical_data)
dummy_features.sample(10, random_state=123)

numeric_data = pd.DataFrame(hotel_data, columns = ['lead_time', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'booking_changes', 'agent', 'adr', 'total_of_special_requests'])
# посмотрим на первые пять наблюдений
numeric_data.sample(10, random_state=123)

X = pd.concat([numeric_data, dummy_features], axis=1)
X.head()

"""Выделим целевую переменную в y."""

y = hotel_data['is_canceled']

# импортируем необходимый модуль
from sklearn.model_selection import train_test_split
 
# размер тестовой выборки составит 30%
# также зададим точку отсчета для воспроизводимости результата
X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size = 0.3, 
                                                    random_state = 42)
X_train.head(3)

"""**Заполнение пропусков**

Рассчитаем средние значения признаков в обучающей выборке, и заполним полученными числами пропуски как в тестовом наборе данных, так и в самой обучающей выборке.

Мы будем заполнять средними значениями из обучающей выборки, так как при решении реальной задачи нам будут доступны только данные для обучения.
"""

train_mean = X_train.mean()
train_mean

"""Для заполнения средним значением, передадим на вход методу fillna() полученный ранее набор средних значений для каждого столбца. Опция inplace=True говорит, что мы запишем изменения прямо в существующий массив, а не создадим новый."""

X_train.fillna(train_mean, inplace=True)
X_train.info()

X_test.fillna(train_mean, inplace=True) # заполним пропуски в тестовой выборке 
X_test.info()

"""**Нормировка данных**"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""**Логистическая регрессия.**
 Для логистической регрессии гиперпараметры как правило не так сильно влияют на результат. Запускаем её с параметрами по умолчанию.
"""

from sklearn.metrics import roc_auc_score, roc_curve

def plot_roc_curve(model, X_train, X_test, y_train, y_test):
    y_train_proba = model.predict_proba(X_train)[:, 1]
    y_test_proba = model.predict_proba(X_test)[:, 1]
    

    plt.figure(figsize=(12,10))

    print(f'Train roc-auc: {roc_auc_score(y_train, y_train_proba)}')
    print(f'Test roc-auc: {roc_auc_score(y_test, y_test_proba)}')


    plt.plot(*roc_curve(y_train, y_train_proba)[:2], label='train roc-curve')
    plt.plot(*roc_curve(y_test, y_test_proba)[:2], label='test roc-curve')

    plt.plot([0,1], [0,1], linestyle='--', color='black')
    plt.grid(True)
    plt.legend()
    plt.show()

from sklearn.linear_model import LogisticRegression

model = LogisticRegression().fit(X_train, y_train)
plot_roc_curve(model, X_train, X_test, y_train, y_test)

y_test_proba_LR = model.predict_proba(X_test)[:, 1]
LR_auc = roc_auc_score(y_test, y_test_proba_LR)
print('LogisticRegression: ROC AUC=%.3f' % (LR_auc))

y_pred_LR = model.predict(X_test)
from sklearn.metrics import confusion_matrix
model_matrix_LR = confusion_matrix(y_test, y_pred_LR, labels = [0, 1])
# для удобства создадим датафрейм
model_matrix_LR_df = pd.DataFrame(model_matrix_LR)
model_matrix_LR_df

model_matrix_LR_df = pd.DataFrame(model_matrix_LR, columns = ['Прогноз бронь', 'Прогноз отменен'], index = ['Факт бронь', 'Факт отменен'])
model_matrix_LR_df

from sklearn.metrics import accuracy_score
 
model_accuracy_LR = accuracy_score(y_test, y_pred_LR)
round(model_accuracy_LR, 2)

"""Итак, модель логистической регрессии согласно метрики roc-auc предсказывает верный результат в 81% случаев, accuracy - 77%.

**Выбор модели, подбор гиперпараметра.**

Для подбора оптимального гиперпараметра будем использовать перебор параметра по сетке. Качество будем измерять с помощью кросс-валидации.
Напишем функцию, визуализирующую поиск оптимального гиперпараметра модели по сетке. Для этого используем метод GridSearchCV из sklearn.model_selection.
"""

from sklearn.model_selection import GridSearchCV

def search(X, y, model, param_name, grid, draw=True):
    parameters = {param_name: grid}
    
    CV_model = GridSearchCV(estimator=model, param_grid=parameters, cv=5, scoring='roc_auc', n_jobs=-1)
    CV_model.fit(X, y)
    means = CV_model.cv_results_['mean_test_score']
    error = CV_model.cv_results_['std_test_score']
    
    if draw:
        plt.figure(figsize=(15,8))
        plt.title('choose ' + param_name)


        plt.plot(grid, means, label='mean values of score')

        plt.fill_between(grid, means - 2 * error, means + 2 * error, color='green', label='deviation area between errors')
        plt.legend()
        plt.xlabel('parameter')
        plt.ylabel('roc_auc')
        plt.show()
        
    return means, error

"""Протестируем функцию на KNN и решающем дереве."""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

models = [KNeighborsClassifier(n_jobs=-1)]
param_names = ['n_neighbors']
grids = [np.array(np.linspace(4, 25, 10), dtype='int')]
param_scales = ['ordinary']

for model, param_name, grid, param_scale in zip(models, 
                                                param_names, 
                                                grids, 
                                                param_scales):
    search(X_train, y_train, model, param_name, grid, param_scale)

model = KNeighborsClassifier(n_neighbors=8, n_jobs=-1).fit(X_train, y_train)
plot_roc_curve(model, X_train, X_test, y_train, y_test)

y_test_proba_KN = model.predict_proba(X_test)[:, 1]
KN_auc = roc_auc_score(y_test, y_test_proba_KN)
print('KNeighborsClassifier: ROC AUC=%.3f' % (KN_auc))

y_pred_KN = model.predict(X_test)
from sklearn.metrics import confusion_matrix
model_matrix_KN = confusion_matrix(y_test, y_pred_KN, labels = [0, 1])
# для удобства создадим датафрейм
model_matrix_KN_df = pd.DataFrame(model_matrix_KN)
model_matrix_KN_df

model_matrix_KN_df = pd.DataFrame(model_matrix_KN, columns = ['Прогноз бронь', 'Прогноз отменен'], index = ['Факт бронь', 'Факт отменен'])
model_matrix_KN_df

from sklearn.metrics import accuracy_score
 
model_accuracy_KN = accuracy_score(y_test, y_pred_KN)
round(model_accuracy_KN, 2)

"""KNeighbors дает точность 86,6%  по метрике roc-auc, 81% по метрике accuracy, что показывает преимущество этой модели перед логистической регрессией. 

"""

models = [DecisionTreeClassifier()]
param_names = ['max_depth']
grids = [np.arange(3, 21, 2)]
param_scales = ['ordinary']

for model, param_name, grid, param_scale in zip(models, 
                                                param_names, 
                                                grids, 
                                                param_scales):
    search(X_train, y_train, model, param_name, grid, param_scale)

model = DecisionTreeClassifier(max_depth=12).fit(X_train, y_train)
plot_roc_curve(model, X_train, X_test, y_train, y_test)

y_test_proba_DT = model.predict_proba(X_test)[:, 1]
DT_auc = roc_auc_score(y_test, y_test_proba_DT)
print('DecisionTreeClassifier: ROC AUC=%.3f' % (DT_auc))

y_pred_DT = model.predict(X_test)
from sklearn.metrics import confusion_matrix
model_matrix_DT = confusion_matrix(y_test, y_pred_DT, labels = [0, 1])
# для удобства создадим датафрейм
model_matrix_DT_df = pd.DataFrame(model_matrix_DT)
model_matrix_DT_df

model_matrix_DT_df = pd.DataFrame(model_matrix_DT, columns = ['Прогноз бронь', 'Прогноз отменен'], index = ['Факт бронь', 'Факт отменен'])
model_matrix_DT_df

from sklearn.metrics import accuracy_score
 
model_accuracy_DT = accuracy_score(y_test, y_pred_DT)
round(model_accuracy_DT, 2)

"""Метрика accuaracy показывает одинаковый результат как у решающего дерева, так и у KNN, по  матрице видно, что KNN лучше предсказывает бронь, а решающее дерево - отмену брони.

**Случайный лес.**
 Подберём параметр n_estimators в алгоритме случайный лес. Известно, что случайный лес не переобучается. Поэтому график качества будет монотонно возрастать. Следовательно, необходимо найти минимальное значение n_estimators, при котором качество не изменяется. Поскольку каждое дерево обучается независимо от остальных, достаточно обучить сразу лес из большого количества деревьев, а затем рассмотреть подмножества нужного размера из исходного множества деревьев.
"""

from sklearn.ensemble import RandomForestClassifier

models = [RandomForestClassifier(n_jobs=-1)]
param_names = ['n_estimators']
grids = [[10, 20, 30, 50, 75, 100, 150]]
param_scales = ['ordinary']

for model, param_name, grid, param_scale in zip(models, 
                                                param_names, 
                                                grids, 
                                                param_scales):
    search(X_train, y_train, model, param_name, grid, param_scale)

model = RandomForestClassifier(n_estimators=74, n_jobs=-1).fit(X_train, y_train)
plot_roc_curve(model, X_train, X_test, y_train, y_test)

y_test_proba_RF = model.predict_proba(X_test)[:, 1]
RF_auc = roc_auc_score(y_test, y_test_proba_RF)
print('RandomForestClassifier: ROC AUC=%.3f' % (RF_auc))

y_pred_RF = model.predict(X_test)
from sklearn.metrics import confusion_matrix
model_matrix_RF = confusion_matrix(y_test, y_pred_RF, labels = [0, 1])
# для удобства создадим датафрейм
model_matrix_RF_df = pd.DataFrame(model_matrix_RF)
model_matrix_RF_df

model_matrix_RF_df = pd.DataFrame(model_matrix_RF, columns = ['Прогноз бронь', 'Прогноз отменен'], index = ['Факт бронь', 'Факт отменен'])
model_matrix_RF_df

from sklearn.metrics import accuracy_score
 
model_accuracy_RF = accuracy_score(y_test, y_pred_RF)
round(model_accuracy_RF, 2)

"""Случайный лес дал самый высокий показатель как по метрике accuracy - 86%, так и по roc-auc - 92%. Также более точные прогнозы видны и по матрице ошибок.

Построим таблицу сравнения эффективности алгоритмов по метрикам roc-auc и accuracy:
"""

metrics_df = pd.DataFrame([
    [ '81,5', '86,6', '86,6', '92,3'],
     [ '77', '81', '81', '86']],
columns=['LogisticRegression', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier'],
index=['roc-auc', 'accuracy'])
metrics_df.head()